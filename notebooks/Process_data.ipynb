{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Zpjs6JrVK6JG","outputId":"c7adcbaf-bf12-49b6-a5ea-d377ba11de7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\01.sinhvien.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/01.sinhvien.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\02.diem.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/02.diem.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\03.sinhvien_chungchi.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/03.sinhvien_chungchi.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\04.xeploaiav.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/04.xeploaiav.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\05.ThiSinh.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/05.ThiSinh.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\06.giayxacnhan.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/06.giayxacnhan.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\08.XLHV.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/08.XLHV.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\10.diemrl.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/10.diemrl.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\12.baoluu.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/12.baoluu.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\14.totnghiep.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/14.totnghiep.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\diemrl.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/diemrl.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\diem_Thu.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/diem_Thu.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\sinhvien_dtb_hocky.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/sinhvien_dtb_hocky.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\sinhvien_dtb_toankhoa.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/sinhvien_dtb_toankhoa.csv\n","Đã chuyển đổi thành công: D:\\Du_Doan\\PT_Data_BI\\data\\uit_hocphi_miengiam.xlsx -> D:\\Du_Doan\\PT_Data_BI\\csv_files_data/uit_hocphi_miengiam.csv\n","Hoàn thành chuyển đổi!\n"]}],"source":["import pandas as pd\n","import os\n","import glob\n","\n","# Đường dẫn đến thư mục chứa file Excel\n","input_path = r'D:\\Du_Doan\\PT_Data_BI\\data'  # Thư mục chứa file Excel\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data'  # Thư mục lưu file CSV\n","\n","# Tạo thư mục output nếu chưa tồn tại\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n","\n","# Lấy tất cả file Excel trong thư mục\n","excel_files = glob.glob(input_path + \"/*.xlsx\")\n","\n","# Chuyển đổi từng file\n","for excel_file in excel_files:\n","    try:\n","        # Đọc file Excel\n","        df = pd.read_excel(excel_file, sheet_name=0)\n","\n","        # Tạo tên file CSV\n","        filename = os.path.splitext(os.path.basename(excel_file))[0]\n","        csv_file = output_path + '/' + filename + '.csv'\n","\n","        # Lưu sang CSV với encoding utf-8-sig để hỗ trợ tiếng Việt\n","        df.to_csv(csv_file, index=False, encoding='utf-8-sig')\n","\n","        print(f'Đã chuyển đổi thành công: {excel_file} -> {csv_file}')\n","\n","    except Exception as e:\n","        print(f'Lỗi khi chuyển đổi file {excel_file}: {str(e)}')\n","\n","print('Hoàn thành chuyển đổi!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw_83CBsK6JL","outputId":"d479c84d-f64e-4cd9-9c9d-e1c9475734c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['id', 'mssv', ' namsinh', ' gioitinh', ' noisinh', ' lopsh', ' khoa', ' hedt', ' khoahoc', ' chuyennganh2', ' tinhtrang', ' diachi_tinhtp', 'Column1', '_1', '_2', '_3', '_4', '_5', '_6', '_7', '_8', '_9', '_10', '_11', '_12', '_13', '_14', '_15', '_16', '_17', '_18', '_19', '_20', '_21', '_22', '_23', '_24', '_25', '_26', '_27', '_28', '_29', '_30', '_31', '_32', '_33', '_34', '_35', '_36', '_37', '_38', '_39', '_40', '_41', '_42', '_43', '_44', '_45', '_46', '_47', '_48', '_49', '_50', '_51', '_52', '_53', '_54', '_55', '_56']\n","\n","5 dòng đầu tiên trong dữ liệu:\n"," id                                     mssv   namsinh   gioitinh                noisinh     lopsh    khoa  hedt   khoahoc  chuyennganh2   tinhtrang          diachi_tinhtp Column1  _1  _2  _3  _4  _5  _6  _7  _8  _9 _10 _11 _12 _13 _14 _15 _16 _17 _18 _19 _20 _21 _22 _23 _24 _25 _26 _27 _28 _29 _30 _31 _32 _33 _34 _35 _36 _37 _38 _39 _40 _41 _42 _43 _44 _45 _46 _47 _48 _49 _50 _51 _52 _53 _54 _55 _56\n","1.0 BE375BAAXPvAibaEXe9JDlHA4z2GHJ3/PVStCxR2    1995.0        1.0        TP. Hồ Chí Minh  KTPM0001    CNPM  CQUI       8.0       D480103         3.0  Thành phố Hồ Chí Minh     NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n","2.0 2420ED57XPvAibaEXe/Lh6v1XxTKJa6JLFRUPkLM    1995.0        1.0              Đồng Tháp  HTTT0001    HTTT  CTTT       8.0       D480104         3.0          Huyện Hóc Môn     NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n","3.0 83B76C01XPvAibaEXe/lOccskaOiO2K46r7t4qnt    1994.0        1.0            Hà Nam Ninh  KHMT2013    KHMT  CQUI       8.0       D480101         5.0            Tỉnh Hà Nam     NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n","4.0 91F785ABXPvAibaEXe/lOccskaOiO5y4GbVvuRQu    1995.0        1.0        TP. Hồ Chí Minh  HTTT0001    HTTT  CTTT       8.0       D480104         3.0  Thành phố Hồ Chí Minh     NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n","5.0 007C275DXPvAibaEXe+TFgEDwYNnveOOmOYeYzF6    1995.0        1.0  Thành phố Hồ Chí Minh  MMTT0001  MMT&TT  CQUI       8.0       D480201         8.0  Thành phố Hồ Chí Minh     NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_23068\\2403975647.py:4: DtypeWarning: Columns (22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\01.sinhvien.csv')\n"]}],"source":["################## File sinhvien ################\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\01.sinhvien.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())  # Chuyển danh sách cột thành dạng dễ đọc hơn\n","\n","# In ra 5 dòng đầu tiên\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))  # In ra dữ liệu mà không có chỉ mục\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRaNmiuFK6JL","outputId":"633697ed-5b0a-412b-d19c-c447c5452e7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","5 dòng đầu tiên sau khi xóa cột:\n"," id                                     mssv  namsinh gioitinh                noisinh     lopsh    khoa  hedt  khoahoc chuyennganh2  tinhtrang          diachi_tinhtp\n","1.0 BE375BAAXPvAibaEXe9JDlHA4z2GHJ3/PVStCxR2   1995.0      Nam        TP. Hồ Chí Minh  KTPM0001    CNPM  CQUI   2013.0      D480103        3.0  Thành phố Hồ Chí Minh\n","2.0 2420ED57XPvAibaEXe/Lh6v1XxTKJa6JLFRUPkLM   1995.0      Nam              Đồng Tháp  HTTT0001    HTTT  CTTT   2013.0      D480104        3.0          Huyện Hóc Môn\n","3.0 83B76C01XPvAibaEXe/lOccskaOiO2K46r7t4qnt   1994.0      Nam            Hà Nam Ninh  KHMT2013    KHMT  CQUI   2013.0      D480101        5.0            Tỉnh Hà Nam\n","4.0 91F785ABXPvAibaEXe/lOccskaOiO5y4GbVvuRQu   1995.0      Nam        TP. Hồ Chí Minh  HTTT0001    HTTT  CTTT   2013.0      D480104        3.0  Thành phố Hồ Chí Minh\n","5.0 007C275DXPvAibaEXe+TFgEDwYNnveOOmOYeYzF6   1995.0      Nam  Thành phố Hồ Chí Minh  MMTT0001  MMT&TT  CQUI   2013.0      D480201        8.0  Thành phố Hồ Chí Minh\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16736\\1226399835.py:4: DtypeWarning: Columns (22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\01.sinhvien.csv')\n"]}],"source":["import pandas as pd\n","\n","# Đọc dữ liệu từ file\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\01.sinhvien.csv')\n","# Loại bỏ khoảng trắng ở đầu và cuối các tên cột\n","df.columns = df.columns.str.strip()\n","# Danh sách các cột cần xóa (bao gồm từ Column1 đến _56)\n","columns_to_drop = ['Column1'] + [f'_{i}' for i in range(1, 57)]\n","# Xóa các cột này\n","df = df.drop(columns=columns_to_drop, errors='ignore')\n","# Chuyển đổi cột 'gioitinh' từ 1 -> 'Nam' và 0 -> 'Nữ'\n","df['gioitinh'] = df['gioitinh'].replace({1: 'Nam', 0: 'Nữ'})\n","# Chuyển đổi cột 'khoahoc' từ 8-14 thành 2013-2019\n","df['khoahoc'] = df['khoahoc'].replace({\n","    8: 2013,\n","    9: 2014,\n","    10: 2015,\n","    11: 2016,\n","    12: 2017,\n","    13: 2018,\n","    14: 2019\n","})\n","# In ra 5 dòng đầu tiên sau khi xóa các cột\n","print(\"\\n5 dòng đầu tiên sau khi xóa cột:\")\n","print(df.head().to_string(index=False))\n","\n","# Lưu lại file CSV với mã hóa utf-8-sig\n","df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_sinhvien.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwWa1lJlK6JM","outputId":"5e0d57f2-a7ab-4420-f3ff-15bebaf55611"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['id', 'mssv', ' mamh', ' malop', ' sotc', ' namhoc', ' hocky', ' diem', ' trangthai', ' mamh_tt']\n","\n","20 dòng đầu tiên trong dữ liệu:\n","      id                                     mssv      mamh              malop   sotc   namhoc   hocky   diem   trangthai  mamh_tt\n","137424.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8    CS1113         CS1113.D11    4.0   2012.0     1.0    0.0         2.0     NULL\n","140865.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     PH001          PH001.D11    4.0   2012.0     1.0    0.0         1.0     NULL\n","141624.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8  ENGL1113   ENGL1113.D11CTTT    3.0   2012.0     1.0    0.0         2.0     NULL\n","141651.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8    ADENG1     ADENG1.D11CTTT    0.0   2012.0     1.0    0.0         2.0     NULL\n","141684.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     SS001      SS001.D11CTTT    5.0   2012.0     1.0    0.0         2.0     NULL\n","141769.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     MA003          MA003.D11    4.0   2012.0     1.0    0.0         1.0     NULL\n","143146.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     MA001          MA001.D11    4.0   2012.0     1.0    0.0         1.0     NULL\n","144710.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     IT001          IT001.D11    4.0   2012.0     1.0    0.0         1.0     NULL\n","145336.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     PE001          PE001.D11    0.0   2012.0     1.0    0.0         1.0     NULL\n","147780.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8  MATH2144  MATH2144.D11.CTTT    4.0   2012.0     1.0    0.0         2.0     NULL\n","168278.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     PE002      PE002.D210.CL    0.0   2012.0     2.0    0.0         1.0     NULL\n","179468.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8  SPCH3724  SPCH3724.D31.CTTT    3.0   2012.0     3.0    0.0         2.0     NULL\n","188378.0 599DFFB8XPvAibaEXe879+AOg1gh8lJvChSN7o+V     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    2.5         2.0     NULL\n","188379.0 FC77E598XPvAibaEXe879+AOg1gh8pb/q8KzJ2A3     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    7.0         1.0     NULL\n","188380.0 51E1C3E0XPvAibaEXe+4hxKfaQWuhLp2zzmiiyRe     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    7.0         1.0     NULL\n","188381.0 6920B9AAXPvAibaEXe83EtiN4MI2ns6NZhlUAIhE     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    5.5         1.0     NULL\n","188382.0 2F237AA9XPvAibaEXe/YKAlYnC3m967dOM4WK2IJ     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    4.5         2.0     NULL\n","188383.0 6AEF2EC0XPvAibaEXe86736b6Ol+/EwtIJHvLVRJ     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    4.5         2.0     NULL\n","188384.0 6F75613CXPvAibaEXe8/3iNqySORbxrmFjIeDct7     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    5.5         1.0     NULL\n","188385.0 41EBF544XPvAibaEXe8/3iNqySORb+za0yWMmptx     IT001     IT001.E11.ANTT    4.0   2013.0     1.0    5.5         1.0     NULL\n"]}],"source":["################## File diem ################\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\02.diem.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())\n","# In ra 20 dòng đầu tiên\n","print(\"\\n20 dòng đầu tiên trong dữ liệu:\")\n","print(df.head(20).to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIhSurwhK6JM","outputId":"88766484-7fbc-458b-c53d-b63dc118b7b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","5 dòng đầu tiên sau khi xóa cột và chuyển đổi giá trị 'trangthai':\n","      id                                     mssv      mamh             malop  sotc  namhoc  hocky  diem   trangthai\n","137424.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8    CS1113        CS1113.D11   4.0  2012.0    1.0   0.0      trả nợ\n","140865.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     PH001         PH001.D11   4.0  2012.0    1.0   0.0 bình thường\n","141624.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8  ENGL1113  ENGL1113.D11CTTT   3.0  2012.0    1.0   0.0      trả nợ\n","141651.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8    ADENG1    ADENG1.D11CTTT   0.0  2012.0    1.0   0.0      trả nợ\n","141684.0 31D5D488XPvAibaEXe85Kg8gbEhwbxD0x3mi2el8     SS001     SS001.D11CTTT   5.0  2012.0    1.0   0.0      trả nợ\n"]}],"source":["import pandas as pd\n","\n","# Đọc dữ liệu từ file\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\02.diem.csv')\n","\n","# Loại bỏ khoảng trắng ở đầu và cuối các tên cột\n","df.columns = df.columns.str.strip()\n","\n","# Danh sách các cột cần xóa (bao gồm từ mamh_tt)\n","columns_to_drop = ['mamh_tt']\n","# Xóa các cột này\n","df = df.drop(columns=columns_to_drop, errors='ignore')\n","# Chuyển đổi cột 'trangthai' từ số thành chuỗi\n","df['trangthai'] = df['trangthai'].replace({\n","    0: 'hủy',\n","    1: 'bình thường',\n","    2: 'trả nợ',\n","    3: 'cải thiện',\n","    4: 'Miễn',\n","    5: 'Hoãn'\n","})\n","\n","# In ra 5 dòng đầu tiên sau khi xóa các cột và chuyển đổi giá trị 'trangthai'\n","print(\"\\n5 dòng đầu tiên sau khi xóa cột và chuyển đổi giá trị 'trangthai':\")\n","print(df.head().to_string(index=False))\n","\n","# Lưu lại file CSV với mã hóa utf-8-sig\n","df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_diem.csv', index=False, encoding='utf-8-sig')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRr5JNGXK6JN","outputId":"1b1b002b-9f28-4ae7-e7f3-6f3d17310b51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['id', 'mssv', ' tinhtrang', ' lydo', ' hocky', ' namhoc', ' soqd', ' ngayqd', 'Column1']\n","\n","5 dòng đầu tiên trong dữ liệu:\n","    id                                     mssv   tinhtrang                                       lydo   hocky   namhoc           soqd     ngayqd Column1\n","7595.0 98247E19XPvAibaEXe93PEySAJOVkxsz+HIviyYJ         2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3     2.0   2016.0  189/QĐ-ĐHCNTT 2017-04-18     NaN\n","7596.0 52B1CC2DXPvAibaEXe+kwIr/VXjl0w+FyuW1abQ7         2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3     2.0   2016.0  189/QĐ-ĐHCNTT 2017-04-18     NaN\n","7597.0 5666EAF4XPvAibaEXe+Z7KfNHYLttJaLI+SH+DpO         2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3     2.0   2016.0  189/QĐ-ĐHCNTT 2017-04-18     NaN\n","7598.0 682C32E0XPvAibaEXe/Bn5cQSu92WX0DcIKdud8D         2.0  Bị cảnh cáo vì ĐTB 2 học kỳ liên tiếp < 4     2.0   2016.0  189/QĐ-ĐHCNTT 2017-04-18     NaN\n","7599.0 7901D3A9XPvAibaEXe+6MN9FoW2mqYEmruXXBNsS         2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3     2.0   2016.0  189/QĐ-ĐHCNTT 2017-04-18     NaN\n"]}],"source":["############# File XLHV ################\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\08.XLHV.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())\n","# In ra 5 dòng đầu tiên\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdJUBuafK6JN","outputId":"51c1b269-5af4-4918-e05e-0b7344057261"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_23068\\2066459351.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2017' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  df.loc[idx, 'namhoc'] = row['soqd']  # Dời giá trị của 'soqd' vào 'namhoc'\n"]},{"name":"stdout","output_type":"stream","text":["Dữ liệu sau khi xử lý:\n","    id                                     mssv  tinhtrang                                       lydo  hocky  namhoc           soqd     ngayqd\n","7595.0 98247E19XPvAibaEXe93PEySAJOVkxsz+HIviyYJ        2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3    2.0  2016.0  189/QĐ-ĐHCNTT 18/04/2017\n","7596.0 52B1CC2DXPvAibaEXe+kwIr/VXjl0w+FyuW1abQ7        2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3    2.0  2016.0  189/QĐ-ĐHCNTT 18/04/2017\n","7597.0 5666EAF4XPvAibaEXe+Z7KfNHYLttJaLI+SH+DpO        2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3    2.0  2016.0  189/QĐ-ĐHCNTT 18/04/2017\n","7598.0 682C32E0XPvAibaEXe/Bn5cQSu92WX0DcIKdud8D        2.0  Bị cảnh cáo vì ĐTB 2 học kỳ liên tiếp < 4    2.0  2016.0  189/QĐ-ĐHCNTT 18/04/2017\n","7599.0 7901D3A9XPvAibaEXe+6MN9FoW2mqYEmruXXBNsS        2.0            Bị cảnh cáo vì ĐTB học kỳ 1 < 3    2.0  2016.0  189/QĐ-ĐHCNTT 18/04/2017\n"]}],"source":["import pandas as pd\n","\n","# Đọc file\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\08.XLHV.csv')\n","\n","# Loại bỏ khoảng trắng ở tên cột\n","df.columns = df.columns.str.strip()\n","\n","# Xử lý các hàng bị thụt lùi (cột hocky bị trống)\n","for idx, row in df.iterrows():\n","    if pd.isnull(row['hocky']):  # Nếu cột 'hocky' bị trống\n","        df.loc[idx, 'hocky'] = row['namhoc']  # Dời giá trị của 'namhoc' vào 'hocky'\n","        df.loc[idx, 'namhoc'] = row['soqd']  # Dời giá trị của 'soqd' vào 'namhoc'\n","        df.loc[idx, 'soqd'] = row['ngayqd']  # Dời giá trị của 'ngayqd' vào 'soqd'\n","\n","        # Chỉ dời giá trị từ Column1 sang ngayqd nếu Column1 có dữ liệu\n","        if not pd.isnull(row['Column1']):\n","            df.loc[idx, 'ngayqd'] = row['Column1']\n","\n","# Xóa cột 'Column1'\n","if 'Column1' in df.columns:\n","    df = df.drop(columns=['Column1'])\n","\n","# Chuẩn hóa cột ngày 'ngayqd'\n","df['ngayqd'] = pd.to_datetime(df['ngayqd'], errors='coerce', dayfirst=False).dt.strftime('%d/%m/%Y')\n","\n","# Lưu lại dữ liệu đã xử lý\n","df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_XLHV.csv', index=False, encoding='utf-8-sig')\n","\n","# Kiểm tra dữ liệu sau xử lý\n","print(\"Dữ liệu sau khi xử lý:\")\n","print(df.head().to_string(index=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsI9nYY4K6JO","outputId":"a82f576e-84c0-486b-9a8f-952d4f060c46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['id', 'mssv', ' xeploai', ' soquyetdinh', ' ngaycapvb']\n","\n","5 dòng đầu tiên trong dữ liệu:\n","     id                                     mssv  xeploai    soquyetdinh   ngaycapvb\n","76328.0 E95E7C6DXPvAibaEXe+1j/AqdkpM22DHf6P99fDJ      Khá  178/QĐ_ĐHCNTT  14/04/2017\n","76663.0 D0FE4969XPvAibaEXe/yXiKgsgy0slCmJ5EKt6Ki     Giỏi  713/QĐ_ĐHCNTT  06/10/2017\n","76664.0 40F7E8D0XPvAibaEXe+nZBq3b0XEhfcwXLmoc4Pj     Giỏi  713/QĐ_ĐHCNTT  06/10/2017\n","76665.0 0A049F45XPvAibaEXe9CtFSNMbfIz9qE7i0Fu4My      Khá  713/QĐ_ĐHCNTT  06/10/2017\n","76666.0 7A7166DAXPvAibaEXe83V/kFvw2bBZ0o/KVHZc30      Khá  713/QĐ_ĐHCNTT  06/10/2017\n"]}],"source":["############# File TOTNGHIEP ################\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\14.totnghiep.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())\n","# In ra 5 dòng đầu tiên\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHZi-UfPK6JO","outputId":"8eb7ffc3-d1e7-4576-b43d-c9c2c7bda2f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","5 dòng đầu tiên sau khi xử lý:\n","     id                                     mssv xeploai    soquyetdinh  ngaycapvb\n","76328.0 E95E7C6DXPvAibaEXe+1j/AqdkpM22DHf6P99fDJ     Khá  178/QĐ_ĐHCNTT 14/04/2017\n","76663.0 D0FE4969XPvAibaEXe/yXiKgsgy0slCmJ5EKt6Ki    Giỏi  713/QĐ_ĐHCNTT 06/10/2017\n","76664.0 40F7E8D0XPvAibaEXe+nZBq3b0XEhfcwXLmoc4Pj    Giỏi  713/QĐ_ĐHCNTT 06/10/2017\n","76665.0 0A049F45XPvAibaEXe9CtFSNMbfIz9qE7i0Fu4My     Khá  713/QĐ_ĐHCNTT 06/10/2017\n","76666.0 7A7166DAXPvAibaEXe83V/kFvw2bBZ0o/KVHZc30     Khá  713/QĐ_ĐHCNTT 06/10/2017\n"]}],"source":["import pandas as pd\n","\n","# Đọc file\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\14.totnghiep.csv')\n","\n","# Loại bỏ khoảng trắng ở tên cột\n","df.columns = df.columns.str.strip()\n","\n","# Xóa các ký tự không mong muốn trong cột 'ngaycapvb' (ví dụ dấu chấm phẩy, dấu ngoặc)\n","df['ngaycapvb'] = df['ngaycapvb'].str.replace(r'[;:)]', '', regex=True).str.strip()\n","\n","# Chuẩn hóa cột 'ngaycapvb' thành định dạng DD/MM/YYYY và đảm bảo ngày/tháng có 2 chữ số\n","def standardize_date(date):\n","    if pd.isna(date):  # Kiểm tra nếu là NaN\n","        return date  # Nếu NaN, trả lại NaN\n","    try:\n","        # Chuyển đổi ngày tháng thành datetime và đảm bảo đúng định dạng\n","        return pd.to_datetime(date, dayfirst=True).strftime('%d/%m/%Y')\n","    except Exception as e:\n","        return date  # Nếu gặp lỗi, trả lại giá trị gốc\n","\n","# Áp dụng chuẩn hóa ngày\n","df['ngaycapvb'] = df['ngaycapvb'].apply(standardize_date)\n","\n","# Kiểm tra 5 dòng đầu tiên sau khi xử lý\n","print(\"\\n5 dòng đầu tiên sau khi xử lý:\")\n","print(df.head().to_string(index=False))\n","\n","# Lưu lại file CSV đã xử lý\n","df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_totnghiep.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLzKB2LPK6JP","outputId":"8f3d034e-fc62-4945-8e25-b10252eb508a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['mssv', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy']\n","\n","5 dòng đầu tiên trong dữ liệu:\n","                                    mssv  dtb_toankhoa  dtb_tichluy  sotc_tichluy\n","C410FEC4XPvAibaEXe/odi52as1TQ/z6UAtEIyTx          7.00         7.00         144.0\n","4555C74CXPvAibaEXe8UBGVVSBKSkjQKdKZAX7FE          6.34         6.34         153.0\n","6FB8C971XPvAibaEXe8zjuWfAVBr9Syz83phZPbU          2.31         0.00           0.0\n","7D7299A4XPvAibaEXe9hYalhCsDQbVspsqAf44vo          8.21         8.21         148.0\n","590263C4XPvAibaEXe9mDsFtgVHJ/lr5wIkYTfyo          8.32         8.32         148.0\n"]}],"source":["############# File ĐTB_TOANKHOA ################\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\sinhvien_dtb_toankhoa.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())\n","# In ra 5 dòng đầu tiên\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZ7OmZYoK6JP","outputId":"10cd4841-7152-4a2f-8114-bde5e7fa8a01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Số lượng giá trị thiếu trong mỗi cột:\n","mssv              0\n","dtb_toankhoa    322\n","dtb_tichluy     322\n","sotc_tichluy    322\n","dtype: int64\n","\n","Kích thước dữ liệu sau khi xóa các hàng chứa giá trị thiếu:\n","(13648, 4)\n","\n","5 dòng đầu tiên sau khi xử lý:\n","                                    mssv  dtb_toankhoa  dtb_tichluy  sotc_tichluy\n","C410FEC4XPvAibaEXe/odi52as1TQ/z6UAtEIyTx          7.00         7.00         144.0\n","4555C74CXPvAibaEXe8UBGVVSBKSkjQKdKZAX7FE          6.34         6.34         153.0\n","6FB8C971XPvAibaEXe8zjuWfAVBr9Syz83phZPbU          2.31         0.00           0.0\n","7D7299A4XPvAibaEXe9hYalhCsDQbVspsqAf44vo          8.21         8.21         148.0\n","590263C4XPvAibaEXe9mDsFtgVHJ/lr5wIkYTfyo          8.32         8.32         148.0\n"]}],"source":["import pandas as pd\n","\n","# Đọc file\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\sinhvien_dtb_toankhoa.csv')\n","\n","# Kiểm tra các giá trị thiếu\n","print(\"Số lượng giá trị thiếu trong mỗi cột:\")\n","print(df.isnull().sum())\n","\n","# Xóa các hàng chứa giá trị thiếu\n","df_cleaned = df.dropna()\n","\n","# Kiểm tra lại kích thước sau khi xóa\n","print(\"\\nKích thước dữ liệu sau khi xóa các hàng chứa giá trị thiếu:\")\n","print(df_cleaned.shape)\n","\n","# Lưu lại file đã xử lý\n","df_cleaned.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_dtb_toankhoa.csv', index=False, encoding='utf-8-sig')\n","\n","# Kiểm tra 5 dòng đầu tiên sau khi xử lý\n","print(\"\\n5 dòng đầu tiên sau khi xử lý:\")\n","print(df_cleaned.head().to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Gs21yo4K6JP","outputId":"b679caa7-2e53-4353-913b-bc42ab3a53a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['id', 'mssv', ' ngaythi', ' url', ' loaixn', ' url_1', ' loaixn_2', ' listening', ' speaking', ' reading', ' writing', ' tongdiem', ' lydo', ' trangthai', ' ngayxl', 'Column1']\n","\n","5 dòng đầu tiên trong dữ liệu:\n","  id                                     mssv  ngaythi                                                         url  loaixn   url_1   loaixn_2   listening   speaking  reading  writing  tongdiem                 lydo  trangthai   ngayxl Column1\n"," 6.0 12C24162XPvAibaEXe9Xnw4t0GPgx9K2sCLXkxKl      NaN  bangcap/13521066/13521066_bangcap_TOIEC_20170627213927.jpg   TOIEC     NaN        NaN         NaN        NaN      NaN                  1  2017-09-08 13:56:09        NaN      NaN     NaN\n"," 8.0 9095EEE4XPvAibaEXe93PEySAJOVk2kOrJQCpxlr      NaN  bangcap/13520021/13520021_bangcap_TOIEC_20170709201640.jpg   TOIEC     NaN        NaN         NaN        NaN      NaN                  1  2017-09-08 13:55:15        NaN      NaN     NaN\n","13.0 538FDEFEXPvAibaEXe9P07hcrvmhCe3unM2XvNXE      NaN  bangcap/13520066/13520066_bangcap_TOIEC_20170728135316.jpg   TOIEC     NaN        NaN         NaN        NaN      NaN                  1  2017-09-08 13:55:27        NaN      NaN     NaN\n","14.0 82EB45E9XPvAibaEXe9eSUilQ3V71rLMOFZnU1bQ      NaN  bangcap/13520828/13520828_bangcap_TOIEC_20170729083204.jpg   TOIEC     NaN        NaN         NaN        NaN      NaN                  1  2017-09-08 13:56:00        NaN      NaN     NaN\n","15.0 DDB9E00CXPvAibaEXe/Xn8KZjn44cdZNDzzd5bIQ      NaN  bangcap/13520576/13520576_bangcap_TOIEC_20170729093319.jpg   TOIEC     NaN        NaN         NaN        NaN      NaN                  1  2017-09-08 13:55:51        NaN      NaN     NaN\n"]}],"source":["################# FILE sinhvien_chungchi ################\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\03.sinhvien_chungchi.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())\n","# In ra 5 dòng đầu tiên\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z80shfhBK6JP","outputId":"19e442e4-ca1e-4d42-8066-3d714b6af046"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16736\\1582828458.py:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value ' 2017-09-08 13:56:09' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  df.at[index, 'ngayxl'] = row['lydo']  # Dời từ 'lydo' sang 'ngayxl'\n"]},{"name":"stdout","output_type":"stream","text":["\n","5 dòng đầu tiên sau khi xử lý:\n","  id                                     mssv ngaythi                                                         url loaixn  url_1  loaixn_2  listening  speaking reading writing tongdiem lydo trangthai               ngayxl\n"," 6.0 12C24162XPvAibaEXe9Xnw4t0GPgx9K2sCLXkxKl     NaN  bangcap/13521066/13521066_bangcap_TOIEC_20170627213927.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:56:09\n"," 8.0 9095EEE4XPvAibaEXe93PEySAJOVk2kOrJQCpxlr     NaN  bangcap/13520021/13520021_bangcap_TOIEC_20170709201640.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:55:15\n","13.0 538FDEFEXPvAibaEXe9P07hcrvmhCe3unM2XvNXE     NaN  bangcap/13520066/13520066_bangcap_TOIEC_20170728135316.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:55:27\n","14.0 82EB45E9XPvAibaEXe9eSUilQ3V71rLMOFZnU1bQ     NaN  bangcap/13520828/13520828_bangcap_TOIEC_20170729083204.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:56:00\n","15.0 DDB9E00CXPvAibaEXe/Xn8KZjn44cdZNDzzd5bIQ     NaN  bangcap/13520576/13520576_bangcap_TOIEC_20170729093319.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:55:51\n"]}],"source":["import pandas as pd\n","\n","# Đọc dữ liệu từ file\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\03.sinhvien_chungchi.csv')\n","\n","# Loại bỏ khoảng trắng ở đầu và cuối tên các cột\n","df.columns = df.columns.str.strip()\n","\n","# Dời dữ liệu giữa các cột mà không bị ghi đè\n","for index, row in df.iterrows():\n","    if pd.notna(row['url_1']):\n","        df.at[index, 'listening'] = row['url_1']  # Dời từ 'url_1' sang 'listening'\n","    if pd.notna(row['loaixn_2']):\n","        df.at[index, 'speaking'] = row['loaixn_2']  # Dời từ 'loaixn_2' sang 'speaking'\n","    if pd.notna(row['listening']):\n","        df.at[index, 'reading'] = row['listening']  # Dời từ 'listening' sang 'reading'\n","    if pd.notna(row['speaking']):\n","        df.at[index, 'writing'] = row['speaking']  # Dời từ 'speaking' sang 'writing'\n","    if pd.notna(row['writing']):\n","        df.at[index, 'lydo'] = row['writing']  # Dời từ 'writing' sang 'lydo'\n","    if pd.notna(row['tongdiem']):\n","        df.at[index, 'trangthai'] = row['tongdiem']  # Dời từ 'tongdiem' sang 'trangthai'\n","    if pd.notna(row['lydo']):\n","        df.at[index, 'ngayxl'] = row['lydo']  # Dời từ 'lydo' sang 'ngayxl'\n","\n","# Xóa cột 'Column1' nếu tồn tại\n","if 'Column1' in df.columns:\n","    df = df.drop(columns=['Column1'])\n","\n","# Kiểm tra 5 dòng đầu tiên sau khi xử lý\n","print(\"\\n5 dòng đầu tiên sau khi xử lý:\")\n","print(df.head().to_string(index=False))\n","\n","# Lưu lại file đã xử lý\n","df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_chungchi.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlydUhenK6JQ","outputId":"dd53f43f-1ec4-4462-8535-d82b92488773"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu:\n","['id', 'mssv', 'ngaythi', 'url', 'loaixn', 'url_1', 'loaixn_2', 'listening', 'speaking', 'reading', 'writing', 'tongdiem', 'lydo', 'trangthai', 'ngayxl']\n","\n","5 dòng đầu tiên trong dữ liệu:\n","  id                                     mssv ngaythi                                                         url loaixn  url_1  loaixn_2  listening  speaking reading writing tongdiem lydo trangthai               ngayxl\n"," 6.0 12C24162XPvAibaEXe9Xnw4t0GPgx9K2sCLXkxKl     NaN  bangcap/13521066/13521066_bangcap_TOIEC_20170627213927.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:56:09\n"," 8.0 9095EEE4XPvAibaEXe93PEySAJOVk2kOrJQCpxlr     NaN  bangcap/13520021/13520021_bangcap_TOIEC_20170709201640.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:55:15\n","13.0 538FDEFEXPvAibaEXe9P07hcrvmhCe3unM2XvNXE     NaN  bangcap/13520066/13520066_bangcap_TOIEC_20170728135316.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:55:27\n","14.0 82EB45E9XPvAibaEXe9eSUilQ3V71rLMOFZnU1bQ     NaN  bangcap/13520828/13520828_bangcap_TOIEC_20170729083204.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:56:00\n","15.0 DDB9E00CXPvAibaEXe/Xn8KZjn44cdZNDzzd5bIQ     NaN  bangcap/13520576/13520576_bangcap_TOIEC_20170729093319.jpg  TOIEC    NaN       NaN        NaN       NaN     NaN                1              1  2017-09-08 13:55:51\n"]}],"source":["############## TIẾP TỤC XỬ LÍ #############\n","\n","import pandas as pd\n","\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_chungchi.csv')\n","\n","# In ra tên các cột\n","print(\"Danh sách các cột trong dữ liệu:\")\n","print(df.columns.tolist())\n","# In ra 5 dòng đầu tiên\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYZoLjHgK6JQ","outputId":"5d35f9fd-2656-4e1d-fa3f-13e51fb72316"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu sau khi xử lý:\n","['id', 'mssv', 'url', 'loaixn', 'listening', 'speaking', 'reading', 'writing', 'lydo', 'trangthai', 'ngayxl', 'tongdiem_toeic', 'ccdr']\n","\n","Các giá trị độc nhất trong cột loaixn sau khi xử lý:\n","['TOIEC' 'TOEIC_LR' 'VNU-EPT' 'IELTS' 'NHAT' 'Cambrigde' 'TOEIC_SW'\n"," 'TOEFL iBT' 'DGNL']\n","\n","5 dòng đầu tiên trong dữ liệu sau khi xử lý:\n","  id                                     mssv                                                         url loaixn  listening  speaking  reading  writing lydo trangthai               ngayxl tongdiem_toeic   ccdr\n"," 6.0 12C24162XPvAibaEXe9Xnw4t0GPgx9K2sCLXkxKl  bangcap/13521066/13521066_bangcap_TOIEC_20170627213927.jpg  TOIEC        NaN       NaN      NaN      NaN              1  2017-09-08 13:56:09              1 NOT_OK\n"," 8.0 9095EEE4XPvAibaEXe93PEySAJOVk2kOrJQCpxlr  bangcap/13520021/13520021_bangcap_TOIEC_20170709201640.jpg  TOIEC        NaN       NaN      NaN      NaN              1  2017-09-08 13:55:15              1 NOT_OK\n","13.0 538FDEFEXPvAibaEXe9P07hcrvmhCe3unM2XvNXE  bangcap/13520066/13520066_bangcap_TOIEC_20170728135316.jpg  TOIEC        NaN       NaN      NaN      NaN              1  2017-09-08 13:55:27              1 NOT_OK\n","14.0 82EB45E9XPvAibaEXe9eSUilQ3V71rLMOFZnU1bQ  bangcap/13520828/13520828_bangcap_TOIEC_20170729083204.jpg  TOIEC        NaN       NaN      NaN      NaN              1  2017-09-08 13:56:00              1 NOT_OK\n","15.0 DDB9E00CXPvAibaEXe/Xn8KZjn44cdZNDzzd5bIQ  bangcap/13520576/13520576_bangcap_TOIEC_20170729093319.jpg  TOIEC        NaN       NaN      NaN      NaN              1  2017-09-08 13:55:51              1 NOT_OK\n","\n","Dữ liệu đã được lưu vào: D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_chungchi_processed.csv\n"]}],"source":["########################## TIẾP TỤC XỬ LÍ #######################\n","import pandas as pd\n","\n","# Đọc file CSV\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_chungchi.csv')\n","\n","# Xóa các hàng có giá trị ngayxl bị thiếu\n","df = df.dropna(subset=['ngayxl'])\n","\n","# Chuẩn hóa cột loaixn - loại bỏ dấu ngoặc đơn và khoảng trắng thừa\n","df['loaixn'] = df['loaixn'].str.replace(\"'\", \"\").str.strip()\n","\n","# Chuyển đổi các cột điểm sang kiểu float\n","numeric_columns = ['listening', 'speaking', 'reading', 'writing']\n","for col in numeric_columns:\n","    df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","# Tạo cột tongdiem mới dựa vào điều kiện loaixn đã được chuẩn hóa\n","df['tongdiem_toeic'] = df.apply(lambda row:\n","    (row['listening'] + row['reading']) if row['loaixn'] == 'TOEIC_LR'\n","    else (row['speaking'] + row['writing']) if row['loaixn'] == 'TOEIC_SW'\n","    else row['tongdiem'], axis=1)\n","\n","\n","# Xóa các cột không cần thiết\n","columns_to_drop = ['ngaythi', 'url_1', 'loaixn_2', 'tongdiem']\n","df = df.drop(columns=columns_to_drop)\n","\n","# In ra tên các cột sau khi xử lý\n","print(\"Danh sách các cột trong dữ liệu sau khi xử lý:\")\n","print(df.columns.tolist())\n","\n","# In thêm một số thống kê để kiểm tra\n","print(\"\\nCác giá trị độc nhất trong cột loaixn sau khi xử lý:\")\n","print(df['loaixn'].unique())\n","\n","# In ra 5 dòng đầu tiên sau khi xử lý\n","print(\"\\n5 dòng đầu tiên trong dữ liệu sau khi xử lý:\")\n","print(df.head().to_string(index=False))\n","\n","# Lưu DataFrame đã xử lý vào file CSV mới\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_chungchi_processed.csv'\n","df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","print(f\"\\nDữ liệu đã được lưu vào: {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUI0tgg7K6JQ","outputId":"df119895-b740-4ed7-9c7d-ee6ee915f6a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["5 dòng đầu tiên sau khi thêm cột ccdr:\n","  trangthai chungchi_av\n","0         1           1\n","1         1           1\n","2         1           1\n","3         1           1\n","4         1           1\n","5         1           1\n","6         1           1\n","7         1           1\n","8         1           1\n","9         1           1\n","\n","Đã lưu file thành công!\n"]}],"source":["############################ TIẾP TỤC XỬ LÍ #################\n","import pandas as pd\n","\n","# Đọc file CSV đã xử lý\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_chungchi_processed.csv')\n","\n","# Tạo cột ccdr mới dựa vào điều kiện của cột trangthai\n","# Sử dụng so sánh với chuỗi '1' thay vì số 1\n","df['chungchi_av'] = df['trangthai'].apply(lambda x: '1' if x == '1' else '0')\n","\n","# In ra 5 dòng đầu tiên để kiểm tra\n","print(\"5 dòng đầu tiên sau khi thêm cột ccdr:\")\n","print(df[['trangthai', 'chungchi_av']].head(10))\n","\n","# Lưu DataFrame với cột mới vào file CSV\n","df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\final_cleaned_sinhvien_chungchi_processed.csv',\n","          index=False,\n","          encoding='utf-8-sig')\n","\n","print(\"\\nĐã lưu file thành công!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKEczw4LK6JQ","outputId":"7aa0aa45-e319-4c09-e15a-3555056e74a9"},"outputs":[{"data":{"text/plain":["'D:\\\\Du_Doan\\\\PT_Data_BI\\\\Data_process\\\\Final_cleaned_data_diemthu.csv'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["############## DIEMTHU #############\n","import pandas as pd\n","\n","# Load the uploaded file to inspect its structure\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\diem_Thu.csv'\n","data = pd.read_csv(file_path)\n","# Group by \"mssv\" and sort by \"namhoc\" and \"hocky\" within each group\n","grouped_data = data.sort_values(by=[\"namhoc\", \"hocky\"]).groupby(\"mssv\")\n","\n","# Initialize a dictionary to store transformed data\n","transformed_data_optimized = []\n","\n","# Process each group\n","for mssv, group in grouped_data:\n","    student_dict = {\"mssv\": mssv, \"trangthai\": group[\"trangthai\"].iloc[0]}\n","    for idx, row in enumerate(group.itertuples(index=False), start=1):\n","        student_dict[f\"diem_hp_hk{idx}\"] = row.diem_hp\n","    transformed_data_optimized.append(student_dict)\n","\n","# Convert to a DataFrame\n","final_data_optimized = pd.DataFrame(transformed_data_optimized)\n","\n","# Save the optimized transformed data to a CSV file\n","output_file = 'D:\\Du_Doan\\PT_Data_BI\\Data_process\\Final_cleaned_data_diemthu.csv'\n","final_data_optimized.to_csv(output_file, index=False)\n","\n","# Output the file path for user to download\n","output_file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2JUsHU8K6JQ"},"outputs":[],"source":["############## DIEMRENLUYEN #############\n","\n","import pandas as pd\n","\n","# Load the uploaded file to inspect its structure\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\diemrl.csv'\n","data = pd.read_csv(file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZb5uNsNK6JR","outputId":"724642be-0b8a-458f-bc23-bc4fdfd8b036"},"outputs":[{"data":{"text/plain":["'D:\\\\Du_Doan\\\\PT_Data_BI\\\\Data_process\\\\clean_data_diemrl.csv'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Group by \"mssv\" and sort by \"namhoc\" and \"hocky\" within each group\n","grouped_data = data.sort_values(by=[\"namhoc\", \"hocky\"]).groupby(\"mssv\")\n","\n","# Initialize a dictionary to store transformed data\n","transformed_data_optimized = []\n","\n","# Process each group\n","for mssv, group in grouped_data:\n","    student_dict = {\"mssv\": mssv, \"lopsh\": group[\"lopsh\"].iloc[0]}  # Keep \"lopsh\" (taking the first value)\n","    for idx, row in enumerate(group.itertuples(index=False), start=1):\n","        student_dict[f\"drl_hk{idx}\"] = row.drl\n","    transformed_data_optimized.append(student_dict)\n","\n","# Convert to a DataFrame\n","final_data_optimized = pd.DataFrame(transformed_data_optimized)\n","\n","# Save the optimized transformed data to a CSV file\n","output_file = 'D:\\Du_Doan\\PT_Data_BI\\Data_process\\clean_data_diemrl.csv'\n","final_data_optimized.to_csv(output_file, index=False)\n","\n","# Output the file path for user to download\n","output_file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uep3zmf3K6JR","outputId":"a258fc97-0e24-4efb-a235-4dd5fffaa20e"},"outputs":[{"data":{"text/plain":["'D:\\\\Du_Doan\\\\PT_Data_BI\\\\Data_process\\\\clean_data_10.diemrl.csv'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Load the uploaded file to inspect its structure\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\10.diemrl.csv'\n","data = pd.read_csv(file_path)\n","# Loại bỏ khoảng trắng ở tên cột\n","data.columns = data.columns.str.strip()\n","# Group by \"mssv\" and sort by \"namhoc\" and \"hocky\" within each group\n","grouped_data = data.sort_values(by=[\"namhoc\", \"hocky\"]).groupby(\"mssv\")\n","\n","# Initialize a dictionary to store transformed data\n","transformed_data_optimized = []\n","\n","# Process each group\n","for mssv, group in grouped_data:\n","    student_dict = {\"mssv\": mssv, \"lopsh\": group[\"lopsh\"].iloc[0]}  # Keep \"lopsh\" (taking the first value)\n","    for idx, row in enumerate(group.itertuples(index=False), start=1):\n","        student_dict[f\"drl_hk{idx}\"] = row.drl\n","    transformed_data_optimized.append(student_dict)\n","\n","# Convert to a DataFrame\n","final_data_optimized = pd.DataFrame(transformed_data_optimized)\n","\n","# Save the optimized transformed data to a CSV file\n","output_file = 'D:\\Du_Doan\\PT_Data_BI\\Data_process\\clean_data_10.diemrl.csv'\n","final_data_optimized.to_csv(output_file, index=False)\n","\n","# Output the file path for user to download\n","output_file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kVK68j5BK6JR","outputId":"15883a5a-f8d9-438b-9e1c-385e42c3245b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tổng số bản ghi unique: 17982\n","\n","Dữ liệu đã được merge:\n","                                           mssv      lopsh  drl_hk1  drl_hk2  \\\n","0      0000AC05XPvAibaEXe9B2tolTZ0JLoBGbkQixQS6   MMCL2021     93.0     90.0   \n","1      0001CF3EXPvAibaEXe/xTpnJlY3K6L35F+TKUux6        NaN     38.0      NaN   \n","0      0001EB57XPvAibaEXe/twT+sf632fUXnsgPGeB4G   TMĐT2019      NaN      NaN   \n","1      00046394XPvAibaEXe+fmxcqgvribEcT4YmJhSFD                 NaN     76.0   \n","4      0006A0BBXPvAibaEXe/lMOwHQdw54DgUkWaqwb1u   KHMT2022     96.0      NaN   \n","...                                         ...        ...      ...      ...   \n","8223   FFE9E452XPvAibaEXe+6MN9FoW2mqXtx1lMTF9+D                 NaN     98.0   \n","8224   FFEF294AXPvAibaEXe/ceziXFRXnLc/x/K0hVw4d   CNTT2017      NaN      NaN   \n","17979  FFF3D630XPvAibaEXe8byJxgVsE7R2dP7ICEdFWK     HTTT04     70.0     70.0   \n","17980  FFF4CD57XPvAibaEXe/z8kRiyNmKNla425pm0Qmc   MTCL2021     97.0     86.0   \n","8225   FFFA4234XPvAibaEXe+OhmjSj4XEzdTGgcTdT9fT   ANTN2016      NaN      NaN   \n","\n","       drl_hk3  drl_hk4  drl_hk5  drl_hk6  drl_hk7  drl_hk8  drl_hk9  \\\n","0        100.0      NaN      NaN      NaN      NaN      NaN      NaN   \n","1          NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n","0          NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n","1         75.0      NaN      NaN      NaN      NaN      NaN      NaN   \n","4          NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n","...        ...      ...      ...      ...      ...      ...      ...   \n","8223      93.0     87.0      NaN      NaN      NaN      NaN      NaN   \n","8224       NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n","17979     85.0     85.0     99.0     99.0     90.0     79.0      NaN   \n","17980     86.0      NaN      NaN      NaN      NaN      NaN      NaN   \n","8225       NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n","\n","       drl_hk10  drl_hk11  drl_hk12  drl_hk13  drl_hk14  diemrl_TB  \n","0           NaN       NaN       NaN       NaN       NaN       94.0  \n","1           NaN       NaN       NaN       NaN       NaN       38.0  \n","0           NaN       NaN       NaN       NaN       NaN        NaN  \n","1           NaN       NaN       NaN       NaN       NaN       76.0  \n","4           NaN       NaN       NaN       NaN       NaN       96.0  \n","...         ...       ...       ...       ...       ...        ...  \n","8223        NaN       NaN       NaN       NaN       NaN       93.0  \n","8224        NaN       NaN       NaN       NaN       NaN        NaN  \n","17979       NaN       NaN       NaN       NaN       NaN       85.0  \n","17980       NaN       NaN       NaN       NaN       NaN       90.0  \n","8225        NaN       NaN       NaN       NaN       NaN        NaN  \n","\n","[17982 rows x 17 columns]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Đọc 2 file CSV\n","df1 = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\clean_data_10.diemrl.csv')\n","df2 = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\clean_data_diemrl.csv')\n","\n","merged_df = pd.concat([df1, df2]).drop_duplicates(subset=['mssv'], keep='first')\n","\n","# Sắp xếp theo mssv\n","merged_df = merged_df.sort_values('mssv')\n","\n","# Tính điểm rèn luyện trung bình và thêm cột mới\n","drl_columns = [col for col in merged_df.columns if col.startswith('drl_hk')]\n","\n","def calculate_avg_drl(row):\n","   valid_scores = [row[col] for col in drl_columns if pd.notna(row[col])]\n","   if valid_scores:\n","       return int(round(sum(valid_scores) / len(valid_scores)))  # Làm tròn và chuyển thành số nguyên\n","   return np.nan\n","\n","merged_df['diemrl_TB'] = merged_df.apply(calculate_avg_drl, axis=1)\n","\n","# Lưu kết quả ra file CSV mới\n","merged_df.to_csv(r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\merged_data_diemrl.csv', index=False, encoding='utf-8-sig')\n","\n","# In thống kê\n","print(f\"Tổng số bản ghi unique: {len(merged_df)}\")\n","print(\"\\nDữ liệu đã được merge:\")\n","print(merged_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzPPh4agK6JR","outputId":"e45c3ce6-71e5-4022-8c82-2c76bb8909f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["['mssv', 'hocky', 'namhoc', 'dtb_hk', 'sotc_hk']\n"]}],"source":["########################## XỬ LÍ FILE DIEMTB_HOCKY ##########################\n","import pandas as pd\n","\n","# Đọc file CSV\n","data = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\sinhvien_dtb_hocky.csv')\n","print(data.columns.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7u48KW6K6JR","outputId":"36dee554-c474-40f4-8353-839ff4f99a91"},"outputs":[{"name":"stdout","output_type":"stream","text":["Kết quả sau khi xử lý:\n","                                       mssv  dtb_hk1  dtb_hk2  dtb_hk3  \\\n","0  0000AC05XPvAibaEXe9B2tolTZ0JLoBGbkQixQS6     7.79     8.28     7.56   \n","1  0001EB57XPvAibaEXe/twT+sf632fUXnsgPGeB4G     8.84     9.00     9.11   \n","2  00046394XPvAibaEXe+fmxcqgvribEcT4YmJhSFD     5.41     7.07     7.75   \n","3  0006A0BBXPvAibaEXe/lMOwHQdw54DgUkWaqwb1u     7.27      NaN      NaN   \n","4  000AD0D8XPvAibaEXe+RQyZpP6sq6qqIPZXybx3Q     8.85     8.64     8.41   \n","\n","   dtb_hk4  dtb_hk5  dtb_hk6  dtb_hk7  dtb_hk8  dtb_hk9  ...  dtb_hk13  \\\n","0     0.00      NaN      NaN      NaN      NaN      NaN  ...       NaN   \n","1     8.75     8.54     8.74     8.41      NaN      NaN  ...       NaN   \n","2     6.36     8.32     7.86     8.09     6.92      7.8  ...       NaN   \n","3      NaN      NaN      NaN      NaN      NaN      NaN  ...       NaN   \n","4     8.05     7.46     7.28     8.55     7.24      NaN  ...       NaN   \n","\n","   dtb_hk14  dtb_hk15  dtb_hk16  dtb_hk17  dtb_hk18  dtb_hk19  dtb_hk20  \\\n","0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n","1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n","2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n","3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n","4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n","\n","   dtb_hk21  dtb_hk22  \n","0       NaN       NaN  \n","1       NaN       NaN  \n","2       NaN       NaN  \n","3       NaN       NaN  \n","4       NaN       NaN  \n","\n","[5 rows x 23 columns]\n","\n","Dữ liệu đã được lưu vào: D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_dtb_hocky.csv\n"]}],"source":["# Group by \"mssv\" and sort by \"namhoc\" and \"hocky\" within each group\n","grouped_data = data.sort_values(by=[\"namhoc\", \"hocky\"]).groupby(\"mssv\")\n","# Initialize a dictionary to store transformed data\n","transformed_data_optimized = []\n","# Process each group\n","for mssv, group in grouped_data:\n","    student_dict = {\"mssv\": mssv}\n","    for idx, row in enumerate(group.itertuples(index=False), start=1):\n","        student_dict[f\"dtb_hk{idx}\"] = row.dtb_hk\n","    transformed_data_optimized.append(student_dict)\n","# Convert to a DataFrame\n","final_data = pd.DataFrame(transformed_data_optimized)\n","# In ra để kiểm tra\n","print(\"Kết quả sau khi xử lý:\")\n","print(final_data.head())\n","# Lưu DataFrame đã xử lý vào file CSV mới\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_dtb_hocky.csv'\n","final_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n","print(f\"\\nDữ liệu đã được lưu vào: {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwr7eZbfK6JR","outputId":"80b85ec2-a7a1-4133-d14f-8a5ea30538fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["['mssv', 'hocky', 'namhoc', 'dtb_hk', 'sotc_hk']\n","Kết quả sau khi xử lý:\n","                                       mssv  sotc_hk1  sotc_hk2  sotc_hk3  \\\n","0  0000AC05XPvAibaEXe9B2tolTZ0JLoBGbkQixQS6        17      21.0      16.0   \n","1  0001EB57XPvAibaEXe/twT+sf632fUXnsgPGeB4G        17      21.0      15.0   \n","2  00046394XPvAibaEXe+fmxcqgvribEcT4YmJhSFD        22      15.0       6.0   \n","3  0006A0BBXPvAibaEXe/lMOwHQdw54DgUkWaqwb1u        14       NaN       NaN   \n","4  000AD0D8XPvAibaEXe+RQyZpP6sq6qqIPZXybx3Q        17      20.0      15.0   \n","\n","   sotc_hk4  sotc_hk5  sotc_hk6  sotc_hk7  sotc_hk8  sotc_hk9  ...  sotc_hk13  \\\n","0       0.0       NaN       NaN       NaN       NaN       NaN  ...        NaN   \n","1      19.0      20.0      20.0       9.0       NaN       NaN  ...        NaN   \n","2      25.0      16.0      14.0      14.0      21.0      11.0  ...        NaN   \n","3       NaN       NaN       NaN       NaN       NaN       NaN  ...        NaN   \n","4      20.0      20.0      19.0      15.0      10.0       NaN  ...        NaN   \n","\n","   sotc_hk14  sotc_hk15  sotc_hk16  sotc_hk17  sotc_hk18  sotc_hk19  \\\n","0        NaN        NaN        NaN        NaN        NaN        NaN   \n","1        NaN        NaN        NaN        NaN        NaN        NaN   \n","2        NaN        NaN        NaN        NaN        NaN        NaN   \n","3        NaN        NaN        NaN        NaN        NaN        NaN   \n","4        NaN        NaN        NaN        NaN        NaN        NaN   \n","\n","   sotc_hk20  sotc_hk21  sotc_hk22  \n","0        NaN        NaN        NaN  \n","1        NaN        NaN        NaN  \n","2        NaN        NaN        NaN  \n","3        NaN        NaN        NaN  \n","4        NaN        NaN        NaN  \n","\n","[5 rows x 23 columns]\n","\n","Dữ liệu đã được lưu vào: D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_sotc_hocky.csv\n"]}],"source":["########################## XỬ LÍ FILE DIEMTB_HOCKY ##########################\n","##################SOTC_HOCKY #######################\n","import pandas as pd\n","\n","# Đọc file CSV\n","data = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\sinhvien_dtb_hocky.csv')\n","print(data.columns.tolist())\n","# Group by \"mssv\" and sort by \"namhoc\" and \"hocky\" within each group\n","grouped_data = data.sort_values(by=[\"namhoc\", \"hocky\"]).groupby(\"mssv\")\n","\n","# Initialize a dictionary to store transformed data\n","transformed_data_optimized = []\n","\n","# Process each group\n","for mssv, group in grouped_data:\n","    student_dict = {\"mssv\": mssv}\n","    for idx, row in enumerate(group.itertuples(index=False), start=1):\n","        student_dict[f\"sotc_hk{idx}\"] = row.sotc_hk\n","    transformed_data_optimized.append(student_dict)\n","\n","# Convert to a DataFrame\n","final_data = pd.DataFrame(transformed_data_optimized)\n","\n","# In ra để kiểm tra\n","print(\"Kết quả sau khi xử lý:\")\n","print(final_data.head())\n","\n","# Lưu DataFrame đã xử lý vào file CSV mới\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_sotc_hocky.csv'\n","final_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n","print(f\"\\nDữ liệu đã được lưu vào: {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsKrJGn5K6JS","outputId":"6f5dd667-4efe-4f81-e805-1ab3597423db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu sau khi xử lý:\n","['id', 'mssv', 'tinhtrang', 'hocky_baoluu', 'namhoc_baoluu', 'soqd', 'ngayqd']\n","\n","5 dòng đầu tiên trong dữ liệu:\n","    id                                     mssv  tinhtrang  hocky_baoluu  namhoc_baoluu            soqd    ngayqd\n","7532.0 E95E7C6DXPvAibaEXe+1j/AqdkpM22DHf6P99fDJ        3.0           2.0         2016.0  178 /QĐ-ĐHCNTT 4/14/2017\n","8304.0 EBC8A649XPvAibaEXe+fmxcqgvribIboSP1ToKmG        3.0           1.0         2017.0   713/QD-DHCNTT 10/6/2017\n","8305.0 2ABBE719XPvAibaEXe9hPQQhQOOPyUJ9WJU9hlCM        3.0           1.0         2017.0   713/QD-DHCNTT 10/6/2017\n","8306.0 C307F053XPvAibaEXe+nZBq3b0XEhX8PABYu6iV1        3.0           1.0         2017.0   713/QD-DHCNTT 10/6/2017\n","8307.0 F99CE6DEXPvAibaEXe86736b6Ol+/O3ZQU1AW1/C        3.0           1.0         2017.0   713/QD-DHCNTT 10/6/2017\n","\n","Dữ liệu đã được lưu vào: D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_baoluu.csv\n"]}],"source":["#############################   XỬ LÍ FILE BAOLUU ###################\n","import pandas as pd\n","\n","# Đọc file CSV\n","df = pd.read_csv(r'D:\\Du_Doan\\PT_Data_BI\\csv_files_data\\12.baoluu.csv')\n","# Loại bỏ khoảng trắng ở tên cột\n","df.columns = df.columns.str.strip()\n","# Xóa cột lydo\n","df = df.drop(columns=['lydo'])\n","\n","# Đổi tên các cột\n","df = df.rename(columns={\n","    'hocky': 'hocky_baoluu',\n","    'namhoc': 'namhoc_baoluu'\n","})\n","\n","# In ra tên các cột để kiểm tra\n","print(\"Danh sách các cột trong dữ liệu sau khi xử lý:\")\n","print(df.columns.tolist())\n","\n","# In ra 5 dòng đầu tiên để kiểm tra\n","print(\"\\n5 dòng đầu tiên trong dữ liệu:\")\n","print(df.head().to_string(index=False))\n","\n","# Lưu DataFrame đã xử lý vào file CSV mới\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_baoluu.csv'\n","df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","print(f\"\\nDữ liệu đã được lưu vào: {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzK2PZlSK6JS","outputId":"a2ca2778-2f2d-42b5-a1a0-57d3d19fd0a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách các cột trong dữ liệu sau khi ghép:\n","['mssv', 'tinhtrang', 'hocky_baoluu', 'namhoc_baoluu', 'drl_hk1', 'drl_hk2', 'drl_hk3', 'drl_hk4', 'drl_hk5', 'drl_hk6', 'drl_hk7', 'drl_hk8', 'drl_hk9', 'drl_hk10', 'drl_hk11', 'drl_hk12', 'drl_hk13', 'drl_hk14', 'diemrl_TB', 'trangthai', 'id', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'chuyennganh2', 'diachi_tinhtp', 'xeploai', 'soquyetdinh', 'ngaycapvb', 'dtb_hk1', 'dtb_hk2', 'dtb_hk3', 'dtb_hk4', 'dtb_hk5', 'dtb_hk6', 'dtb_hk7', 'dtb_hk8', 'dtb_hk9', 'dtb_hk10', 'dtb_hk11', 'dtb_hk12', 'dtb_hk13', 'dtb_hk14', 'dtb_hk15', 'dtb_hk16', 'dtb_hk17', 'dtb_hk18', 'dtb_hk19', 'dtb_hk20', 'dtb_hk21', 'dtb_hk22', 'chungchi_av', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy', 'sotc_hk1', 'sotc_hk2', 'sotc_hk3', 'sotc_hk4', 'sotc_hk5', 'sotc_hk6', 'sotc_hk7', 'sotc_hk8', 'sotc_hk9', 'sotc_hk10', 'sotc_hk11', 'sotc_hk12', 'sotc_hk13', 'sotc_hk14', 'sotc_hk15', 'sotc_hk16', 'sotc_hk17', 'sotc_hk18', 'sotc_hk19', 'sotc_hk20', 'sotc_hk21', 'sotc_hk22']\n","\n","5 dòng đầu tiên sau khi ghép và sắp xếp dữ liệu:\n","                                           mssv  tinhtrang  hocky_baoluu  \\\n","11754  A6066FB1XPvAibaEXe8ydgsBCmjqAwCLOP/9AoDk        3.0           1.0   \n","2028   1D5EC289XPvAibaEXe+1P/4gNbgreeJ2VIlZrW72        NaN           NaN   \n","14171  C6FDC4ACXPvAibaEXe8jolcsAIssTEE3N5g9BgT7        NaN           NaN   \n","14153  C6D87955XPvAibaEXe8ooYk4mkUGmC0EOMKX8NpL        NaN           NaN   \n","16702  E997D336XPvAibaEXe+cD1fKElqxL3Gg+IEXlrlL        NaN           NaN   \n","\n","       namhoc_baoluu  drl_hk1  drl_hk2  drl_hk3  drl_hk4  drl_hk5  drl_hk6  \\\n","11754         2020.0      NaN     79.0     86.0      NaN      NaN      NaN   \n","2028             NaN      NaN     37.0      NaN      NaN      NaN      NaN   \n","14171            NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n","14153            NaN      NaN     82.0     91.0      NaN      NaN      NaN   \n","16702            NaN      NaN     54.0    -30.0      NaN      NaN      NaN   \n","\n","       ...  sotc_hk13  sotc_hk14  sotc_hk15  sotc_hk16  sotc_hk17  sotc_hk18  \\\n","11754  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n","2028   ...        NaN        NaN        NaN        NaN        NaN        NaN   \n","14171  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n","14153  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n","16702  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n","\n","       sotc_hk19  sotc_hk20  sotc_hk21 sotc_hk22  \n","11754        NaN        NaN        NaN       NaN  \n","2028         NaN        NaN        NaN       NaN  \n","14171        NaN        NaN        NaN       NaN  \n","14153        NaN        NaN        NaN       NaN  \n","16702        NaN        NaN        NaN       NaN  \n","\n","[5 rows x 81 columns]\n"]}],"source":["import pandas as pd\n","\n","# Đường dẫn đến các file đã xử lý\n","file_paths = [\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_baoluu.csv',\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\merged_data_diemrl.csv',  # Xử lý đầy đủ file này\n","    r\"D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_diem.csv\",\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_sinhvien.csv',\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_totnghiep.csv',\n","    r\"D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_data_XLHV.csv\",\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_dtb_hocky.csv',\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\final_cleaned_sinhvien_chungchi_processed.csv',\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_dtb_toankhoa.csv',\n","    r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\cleaned_sinhvien_sotc_hocky.csv'\n","]\n","\n","# Đọc tất cả các file và lọc dữ liệu\n","data_frames = []\n","for path in file_paths:\n","    df = pd.read_csv(path)\n","\n","    # Lọc các cột theo yêu cầu dựa vào tên file\n","    if 'baoluu' in path.lower():\n","        df = df[['mssv', 'tinhtrang', 'hocky_baoluu', 'namhoc_baoluu']]\n","    elif 'chungchi' in path.lower():\n","        df = df[['mssv', 'chungchi_av']]\n","    elif 'diem' in path.lower() and 'diemrl' not in path.lower():\n","        if 'trangthai' in df.columns:\n","            df = df[['mssv', 'trangthai']]\n","        else:\n","            print(f\"Cột 'trangthai' không tồn tại trong file: {path}\")\n","            continue\n","    elif 'xlhv' in path.lower():\n","        if 'tinhtrang' in df.columns:\n","            df = df[['mssv', 'tinhtrang']]\n","        else:\n","            print(f\"Cột 'tinhtrang' không tồn tại trong file: {path}\")\n","            continue\n","    elif 'diemrl' in path.lower():  # Xử lý file 'merged_data_diemrl.csv'\n","        if 'mssv' in df.columns:\n","            # Giữ lại các cột liên quan đến điểm rèn luyện\n","            drl_columns = [col for col in df.columns if 'drl_hk' in col or col == 'diemrl_TB']\n","            df = df[['mssv'] + drl_columns]\n","        else:\n","            print(f\"Cột 'mssv' không tồn tại trong file: {path}\")\n","            continue\n","\n","    # Loại bỏ các bản ghi trùng lặp\n","    df = df.drop_duplicates(subset='mssv')\n","    data_frames.append(df)\n","\n","# Ghép dữ liệu dựa trên mssv\n","merged_df = data_frames[0]\n","for df in data_frames[1:]:\n","    merged_df = pd.merge(merged_df, df, on='mssv', how='outer', suffixes=('', '_dup'))\n","\n","# Loại bỏ các cột trùng tên (ví dụ: 'mssv_dup', ...)\n","columns_to_drop = [col for col in merged_df.columns if 'dup' in col]\n","merged_df.drop(columns=columns_to_drop, inplace=True)\n","\n","# Loại bỏ các mssv trùng lặp trong DataFrame sau khi merge\n","merged_df = merged_df.drop_duplicates(subset='mssv')\n","\n","# Sắp xếp theo cột 'khoahoc' (nếu có)\n","if 'khoahoc' in merged_df.columns:\n","    merged_df = merged_df.sort_values(by='khoahoc', ascending=True)\n","\n","# In ra thông tin về các cột trong DataFrame sau khi ghép\n","print(\"Danh sách các cột trong dữ liệu sau khi ghép:\")\n","print(merged_df.columns.tolist())\n","\n","# Lưu lại file sau khi ghép và sắp xếp\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\merged_data.csv'\n","merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","\n","# In ra một số dòng đầu tiên để kiểm tra\n","print(\"\\n5 dòng đầu tiên sau khi ghép và sắp xếp dữ liệu:\")\n","print(merged_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkVQFbW-K6JS","outputId":"dee5227d-679d-4175-c9d4-7723dd753bd8"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_8796\\3756988464.py:5: DtypeWarning: Columns (19,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n","  merged_df = pd.read_csv(file_path)\n"]},{"name":"stdout","output_type":"stream","text":["Danh sách các cột sau khi xử lý:\n","['mssv', 'drl_hk1', 'drl_hk2', 'drl_hk3', 'drl_hk4', 'drl_hk5', 'drl_hk6', 'drl_hk7', 'drl_hk8', 'drl_hk9', 'drl_hk10', 'diemrl_TB', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'chuyennganh2', 'diachi_tinhtp', 'xeploai', 'soquyetdinh', 'ngaycapvb', 'dtb_hk1', 'dtb_hk2', 'dtb_hk3', 'dtb_hk4', 'dtb_hk5', 'dtb_hk6', 'dtb_hk7', 'dtb_hk8', 'dtb_hk9', 'dtb_hk10', 'chungchi_av', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy', 'sotc_hk1', 'sotc_hk2', 'sotc_hk3', 'sotc_hk4', 'sotc_hk5', 'sotc_hk6', 'sotc_hk7', 'sotc_hk8', 'sotc_hk9', 'sotc_hk10']\n","\n","5 dòng đầu tiên của dữ liệu sau khi xử lý:\n","                                       mssv  drl_hk1  drl_hk2  drl_hk3  \\\n","0  A6066FB1XPvAibaEXe8ydgsBCmjqAwCLOP/9AoDk     82.0     79.0     86.0   \n","1  1D5EC289XPvAibaEXe+1P/4gNbgreeJ2VIlZrW72     37.0     37.0     37.0   \n","2  C6FDC4ACXPvAibaEXe8jolcsAIssTEE3N5g9BgT7      NaN      NaN      NaN   \n","3  C6D87955XPvAibaEXe8ooYk4mkUGmC0EOMKX8NpL     86.0     82.0     91.0   \n","4  E997D336XPvAibaEXe+cD1fKElqxL3Gg+IEXlrlL     12.0     54.0    -30.0   \n","\n","   drl_hk4  drl_hk5  drl_hk6  drl_hk7  drl_hk8  drl_hk9  ...  sotc_hk1  \\\n","0     82.0     82.0     82.0     82.0     82.0     82.0  ...      18.0   \n","1     37.0      NaN      NaN      NaN      NaN      NaN  ...      22.0   \n","2      NaN      NaN      NaN      NaN      NaN      NaN  ...      18.0   \n","3     86.0     86.0     86.0     86.0     86.0     86.0  ...      22.0   \n","4     12.0     12.0      NaN      NaN      NaN      NaN  ...      22.0   \n","\n","   sotc_hk2  sotc_hk3 sotc_hk4 sotc_hk5 sotc_hk6 sotc_hk7 sotc_hk8  sotc_hk9  \\\n","0      19.0      24.0     15.0     14.0     24.0     23.0     18.0      24.0   \n","1      16.0      10.0     16.0      NaN      NaN      NaN      NaN       NaN   \n","2       NaN       NaN      NaN      NaN      NaN      NaN      NaN       NaN   \n","3      18.0       7.0     21.0     20.0     16.0     20.0     21.0      13.0   \n","4      21.0      13.0     28.0     26.0      NaN      NaN      NaN       NaN   \n","\n","  sotc_hk10  \n","0       NaN  \n","1       NaN  \n","2       NaN  \n","3      13.0  \n","4       NaN  \n","\n","[5 rows x 48 columns]\n"]}],"source":["import pandas as pd\n","\n","# Đọc dữ liệu gộp\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\merged_data.csv'\n","merged_df = pd.read_csv(file_path)\n","\n","# 1. Cắt dữ liệu từ hàng 8295 trở đi\n","merged_df = merged_df.iloc[:8295]\n","\n","# 2. Xóa các ký tự không mong muốn trong cột `noisinh` và `diachi_tinhtp`\n","merged_df['noisinh'] = merged_df['noisinh'].str.replace(r'[\\'\\\"]', '', regex=True)\n","merged_df['diachi_tinhtp'] = merged_df['diachi_tinhtp'].str.replace(r'[\\'\\\"]', '', regex=True)\n","\n","# 3. Xóa các cột `id`, `dtb_hk11-22`, `sotc_hk11-22`, `drl_hk11-22`, và các cột `tinhtrang`, `hocky_baoluu`, `namhoc_baoluu`, `trangthai`\n","columns_to_drop = (\n","    ['id', 'tinhtrang', 'hocky_baoluu', 'namhoc_baoluu', 'trangthai'] +\n","    [f'dtb_hk{i}' for i in range(11, 23)] +\n","    [f'sotc_hk{i}' for i in range(11, 23)] +\n","    [f'drl_hk{i}' for i in range(11, 23)]\n",")\n","merged_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n","\n","# 4. Thêm giá trị 0 vào cột `chungchi_av` cho những ô khác 1\n","merged_df['chungchi_av'] = merged_df['chungchi_av'].apply(lambda x: 0 if x != 1 else 1)\n","\n","# 5. Cập nhật lại `sotc_tichluy` bằng tổng `sotc_hk` từ `sotc_hk1` đến `sotc_hk10` có giá trị > 0\n","sotc_columns = [f'sotc_hk{i}' for i in range(1, 11)]  # Lấy danh sách các cột `sotc_hk1` đến `sotc_hk10`\n","merged_df['sotc_tichluy'] = merged_df[sotc_columns].apply(lambda row: row[row > 0].sum(), axis=1)\n","\n","# 6. Điền giá trị thiếu cho các cột `drl_hk` dựa trên `dtb_hk` và `sotc_hk`\n","drl_columns = [f'drl_hk{i}' for i in range(1, 11)]\n","dtb_columns = [f'dtb_hk{i}' for i in range(1, 11)]\n","\n","def fill_missing_drl(row):\n","    for i in range(10):  # 10 học kỳ\n","        if pd.isnull(row[drl_columns[i]]):  # Nếu drl_hk bị thiếu\n","            if not (pd.isnull(row[dtb_columns[i]]) or pd.isnull(row[sotc_columns[i]])):\n","                # Tính giá trị drl_hk dựa trên các học kỳ khác của sinh viên (nếu có)\n","                valid_drl = [row[drl] for drl in drl_columns if not pd.isnull(row[drl])]\n","                if valid_drl:  # Có dữ liệu drl_hk khác\n","                    row[drl_columns[i]] = round(sum(valid_drl) / len(valid_drl))  # Làm tròn thành số nguyên\n","    return row\n","\n","merged_df = merged_df.apply(fill_missing_drl, axis=1)\n","\n","# 7. Xóa các dòng nếu sinh viên không có bất kỳ giá trị nào trong `dtb_hk` hoặc `sotc_hk`\n","valid_rows = merged_df[dtb_columns + sotc_columns].notnull().sum(axis=1) > 0  # Kiểm tra ít nhất 1 giá trị khác null\n","merged_df = merged_df[valid_rows]\n","\n","# Lưu lại dữ liệu đã xử lý\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\merged_data_processed.csv'\n","merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","\n","# In ra thông tin dữ liệu sau khi xử lý\n","print(\"Danh sách các cột sau khi xử lý:\")\n","print(merged_df.columns.tolist())\n","print(\"\\n5 dòng đầu tiên của dữ liệu sau khi xử lý:\")\n","print(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HsUdezzK6JS","outputId":"4496a084-1f27-451e-8279-a2b05f804eb2"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_8796\\3685087058.py:45: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n","  ngaycap_nam = pd.to_datetime(row['ngaycapvb'], errors='coerce').year  # Lấy năm từ `ngaycapvb`\n"]},{"name":"stdout","output_type":"stream","text":["Danh sách các cột sau khi xử lý:\n","['mssv', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'chuyennganh2', 'diachi_tinhtp', 'xeploai', 'soquyetdinh', 'ngaycapvb', 'drl_hk1', 'drl_hk2', 'drl_hk3', 'drl_hk4', 'drl_hk5', 'drl_hk6', 'drl_hk7', 'drl_hk8', 'drl_hk9', 'drl_hk10', 'diemrl_TB', 'dtb_hk1', 'dtb_hk2', 'dtb_hk3', 'dtb_hk4', 'dtb_hk5', 'dtb_hk6', 'dtb_hk7', 'dtb_hk8', 'dtb_hk9', 'dtb_hk10', 'chungchi_av', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy', 'sotc_hk1', 'sotc_hk2', 'sotc_hk3', 'sotc_hk4', 'sotc_hk5', 'sotc_hk6', 'sotc_hk7', 'sotc_hk8', 'sotc_hk9', 'sotc_hk10', 'sotc_daura', 'hocky_thu', 'label']\n","\n","5 dòng đầu tiên của dữ liệu sau khi xử lý:\n","                                       mssv  namsinh gioitinh  \\\n","0  A6066FB1XPvAibaEXe8ydgsBCmjqAwCLOP/9AoDk   1995.0      Nam   \n","1  1D5EC289XPvAibaEXe+1P/4gNbgreeJ2VIlZrW72   1995.0      Nam   \n","2  C6FDC4ACXPvAibaEXe8jolcsAIssTEE3N5g9BgT7   1995.0      Nam   \n","3  C6D87955XPvAibaEXe8ooYk4mkUGmC0EOMKX8NpL   1994.0      Nam   \n","4  E997D336XPvAibaEXe+cD1fKElqxL3Gg+IEXlrlL   1995.0      Nam   \n","\n","            noisinh      lopsh     khoa   hedt  khoahoc chuyennganh2  \\\n","0           Phú Yên   KTPM0001     CNPM   CQUI   2013.0      D480103   \n","1          Lâm Đồng   MMTT2013   MMT&TT   CQUI   2013.0      D480102   \n","2   TP. Hồ Chí Minh   HTTT2013     HTTT   CQUI   2013.0      D480104   \n","3           Đắk Lắk   KTMT0001     KTMT   CQUI   2013.0      D520214   \n","4        Bình Thuận   CNTT2013     KTTT   CQUI   2013.0      D480201   \n","\n","      diachi_tinhtp  ... sotc_hk4 sotc_hk5 sotc_hk6  sotc_hk7  sotc_hk8  \\\n","0      Tỉnh Phú Yên  ...     15.0     14.0     24.0      23.0      18.0   \n","1     Tỉnh Lâm Đồng  ...     16.0     -1.0     -1.0      -1.0      -1.0   \n","2      Quận Thủ Đức  ...     -1.0     -1.0     -1.0      -1.0      -1.0   \n","3      Tỉnh Đắk Lắk  ...     21.0     20.0     16.0      20.0      21.0   \n","4   Huyện Tánh Linh  ...     28.0     26.0     -1.0      -1.0      -1.0   \n","\n","   sotc_hk9  sotc_hk10  sotc_daura  hocky_thu  label  \n","0      24.0       -1.0         136        9.0      0  \n","1      -1.0       -1.0         121        4.0      1  \n","2      -1.0       -1.0         140        1.0      1  \n","3      13.0       13.0         156       10.0      0  \n","4      -1.0       -1.0         125        5.0      1  \n","\n","[5 rows x 51 columns]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Đọc dữ liệu gộp\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\merged_data_processed.csv'\n","merged_df = pd.read_csv(file_path)\n","\n","# 1. Tạo cột `sotc_daura` dựa vào mã ngành trong `lopsh`\n","sotc_nganh = {\n","    'CNTT': 125,\n","    'HTTT': 140,\n","    'KHMT': 126,\n","    'KTPM': 136,\n","    'KTMT': 156,\n","    'MMT&TT': 136,\n","    'ATTT': 131,\n","    'TMĐT': 126,\n","    'KHDL': 121\n","}\n","\n","# Ánh xạ mã ngành từ `lopsh` để gán giá trị vào `sotc_daura`\n","def map_sotc_daura(lopsh):\n","    for ma_nganh, sotc in sotc_nganh.items():\n","        if ma_nganh in str(lopsh):  # Kiểm tra nếu mã ngành xuất hiện trong `lopsh`\n","            return sotc\n","    return 121  # Giá trị mặc định nếu không có mã ngành nào khớp\n","\n","merged_df['sotc_daura'] = merged_df['lopsh'].apply(map_sotc_daura)\n","\n","# 2. Tạo cột `hocky_thu` dựa vào `sotc_hk`\n","sotc_columns = [f'sotc_hk{i}' for i in range(1, 11)]  # Cột sotc từ học kỳ 1 đến học kỳ 10\n","\n","def calculate_hocky_thu(row):\n","    for i in range(10, 0, -1):  # Duyệt ngược từ học kỳ 10 về học kỳ 1\n","        if row[f'sotc_hk{i}'] > 0:\n","            return i\n","    return np.nan\n","\n","merged_df['hocky_thu'] = merged_df.apply(calculate_hocky_thu, axis=1)\n","\n","# 3. Tạo cột `label` để gán nhãn\n","def assign_label(row):\n","    # Trường hợp đã có bằng (cột `xeploai` không null)\n","    if pd.notnull(row['xeploai']):\n","        ngaycap_nam = pd.to_datetime(row['ngaycapvb'], errors='coerce').year  # Lấy năm từ `ngaycapvb`\n","        if pd.notnull(ngaycap_nam) and (ngaycap_nam - row['khoahoc'] <= 4) and row['hocky_thu'] <= 8:\n","            return 1  # Tốt nghiệp đúng hạn\n","\n","    # Trường hợp chưa có bằng\n","    if pd.isnull(row['xeploai']):\n","        # Điều kiện `chungchi_av = 1` và tín chỉ tích lũy đủ\n","        if row['hocky_thu'] <= 8 and row['sotc_tichluy'] >= row['sotc_daura']:\n","            return 1  # Tốt nghiệp đúng hạn\n","        # Điều kiện `(sotc_daura - sotc_tichluy) > 0` và <= 24 tín chỉ/học kỳ\n","        elif (row['sotc_daura'] - row['sotc_tichluy']) > 0 and (8 - row['hocky_thu']) > 0:\n","            additional_sotc_per_hk = (row['sotc_daura'] - row['sotc_tichluy']) / (8 - row['hocky_thu'])\n","            if additional_sotc_per_hk <= 24:\n","                return 1  # Tốt nghiệp đúng hạn\n","        # Điều kiện `chungchi_av = 0` nhưng học kỳ vẫn trong giới hạn (<= 8)\n","        if row['hocky_thu'] <= 8 and row['chungchi_av'] == 0:\n","            return 1  # Tốt nghiệp đúng hạn\n","\n","    # Trường hợp còn lại\n","    return 0  # Tốt nghiệp không đúng hạn\n","\n","merged_df['label'] = merged_df.apply(assign_label, axis=1)\n","## Điền giá trị -1 vào những ô còn thiếu\n","merged_df.fillna(-1, inplace=True)\n","# Sắp xếp lại thứ tự cột\n","columns_to_move = ['mssv', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'chuyennganh2', 'diachi_tinhtp', 'xeploai', 'soquyetdinh', 'ngaycapvb']\n","new_column_order = columns_to_move + [col for col in merged_df.columns if col not in columns_to_move]\n","merged_df = merged_df[new_column_order]\n","# Lưu lại dữ liệu đã xử lý\n","output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\final_merged_processed_data.csv'\n","merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","\n","# In ra thông tin dữ liệu sau khi xử lý\n","print(\"Danh sách các cột sau khi xử lý:\")\n","print(merged_df.columns.tolist())\n","print(\"\\n5 dòng đầu tiên của dữ liệu sau khi xử lý:\")\n","print(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGFQimTRK6JS","outputId":"3366aab7-ab9f-4d91-afa1-238cff7efbf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Số lượng giá trị trong cột 'label':\n","label\n","1    4310\n","0    3921\n","Name: count, dtype: int64\n","\n","Phần trăm mỗi giá trị trong cột 'label':\n","label\n","1    52.363018\n","0    47.636982\n","Name: proportion, dtype: float64\n"]}],"source":["import pandas as pd\n","\n","# Đọc dữ liệu đã xử lý\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\final_merged_processed_data.csv'\n","merged_df = pd.read_csv(file_path)\n","\n","# Kiểm tra phân phối các giá trị trong cột `label`\n","label_counts = merged_df['label'].value_counts()\n","\n","# In ra số lượng giá trị trong cột `label`\n","print(\"Số lượng giá trị trong cột 'label':\")\n","print(label_counts)\n","\n","# Tính phần trăm mỗi giá trị (nếu cần)\n","label_percentage = merged_df['label'].value_counts(normalize=True) * 100\n","print(\"\\nPhần trăm mỗi giá trị trong cột 'label':\")\n","print(label_percentage)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtezPYhjK6JT","outputId":"3e73b408-4286-43a7-91e3-dd922451dca2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Train\\train_data.csv\n","Test data for test_hk1 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk2 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk3 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk4 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk5 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk6 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk7 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Test data for test_hk8 saved at: D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\test_hk8.csv\n","Done!\n"]}],"source":["import pandas as pd\n","\n","# Sửa đường dẫn file với định dạng chuỗi thô để tránh lỗi ký tự\n","file_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\final_merged_processed_data.csv'\n","data = pd.read_csv(file_path)\n","\n","# Chuẩn bị dữ liệu train (toàn bộ dữ liệu gốc)\n","train_data = data.copy()\n","\n","# Tạo 8 file test\n","test_files = {}\n","for hk in range(1, 9):\n","    columns_to_keep = [\n","        'mssv', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt',\n","        'khoahoc', 'chuyennganh2', 'diachi_tinhtp', 'chungchi_av', 'dtb_tichluy',\n","        'sotc_tichluy', 'hocky_thu', 'sotc_daura', 'diemrl_TB', 'ngaycapvb', 'label'\n","    ] + [f'dtb_hk{hk}', f'sotc_hk{hk}', f'drl_hk{hk}']  # Giữ lại thông tin của học kỳ hk\n","    test_data = data[columns_to_keep].copy()\n","    test_files[f'test_hk{hk}'] = test_data\n","\n","# Lưu dữ liệu train và test vào các file CSV\n","train_output_path = r'D:\\Du_Doan\\PT_Data_BI\\Data_process\\Train\\train_data.csv'\n","train_data.to_csv(train_output_path, index=False, encoding='utf-8-sig')\n","\n","for hk, df in test_files.items():\n","    test_output_path = f'D:\\Du_Doan\\PT_Data_BI\\Data_process\\Test\\{hk}.csv'\n","    df.to_csv(test_output_path, index=False, encoding='utf-8-sig')\n","\n","# Hiển thị thông tin\n","print(f\"Train data saved at: {train_output_path}\")\n","for hk, df in test_files.items():\n","    print(f\"Test data for {hk} saved at: {test_output_path}\")\n","print(\"Done!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBY7UCTJK6JT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-iLoicfK6JT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3wn9a6XK6JT"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"LamViecPytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}